{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Impact of number of hidden neurons to model performance\n",
    "\n",
    "This notebook investigates how the number of hidden neurons affect the model performance. We will see that increasing the number of hidden neurons increases the performance of a model using the MNIST dataset. The MNIST dataset is a common standard dataset used to evaluate machine learning models performance, which is just a task of recognizing digits from 0 to 9.\n",
    "\n",
    "This notebook has dependencies on Keras, Scikit-Learn and MatPlotLib.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.optimizers import SGD, Adam, RMSprop\n",
    "from sklearn.preprocessing import *\n",
    "from sklearn.cross_validation import *\n",
    "from sklearn.metrics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TRAIN_FILE = 'data/train.csv'\n",
    "TEST_FILE = 'data/test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = np.loadtxt(TRAIN_FILE, skiprows = 1, delimiter = ',', dtype = 'float')\n",
    "X = train_data[:, 1:]\n",
    "# Preprocess the data to make features fall between 0 and 1. Neural networks perform a lot better in this way.\n",
    "X = X/255\n",
    "raw_Y = train_data[:, 0].reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test = np.loadtxt(TEST_FILE, skiprows = 1, delimiter = ',', dtype = 'float')\n",
    "# Preprocess the data to make features fall between 0 and 1. Neural networks perform a lot better in this way.\n",
    "X_test = X_test/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_cv, raw_Y_train, raw_Y_cv = train_test_split(X, raw_Y, test_size = 0.20)\n",
    "\n",
    "# Converter to transform input into one hot encoding, i.e. [3] => [0, 0, 1, 0, 0, 0, 0, 0, 0, 0].\n",
    "# Can use the np_utils from Keras instead.\n",
    "Y_expander = OneHotEncoder().fit(raw_Y)\n",
    "Y_train = Y_expander.transform(raw_Y_train).astype(int).toarray()\n",
    "Y_cv = Y_expander.transform(raw_Y_cv).astype(int).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 31920 samples, validate on 1680 samples\n",
      "Epoch 1/10\n",
      "31920/31920 [==============================] - 3s - loss: 0.4771 - acc: 0.8713 - val_loss: 0.3271 - val_acc: 0.9054\n",
      "Epoch 2/10\n",
      "31920/31920 [==============================] - 3s - loss: 0.3105 - acc: 0.9121 - val_loss: 0.2945 - val_acc: 0.9119\n",
      "Epoch 3/10\n",
      "31920/31920 [==============================] - 3s - loss: 0.2806 - acc: 0.9207 - val_loss: 0.2707 - val_acc: 0.9185\n",
      "Epoch 4/10\n",
      "31920/31920 [==============================] - 3s - loss: 0.2605 - acc: 0.9250 - val_loss: 0.2533 - val_acc: 0.9232\n",
      "Epoch 5/10\n",
      "31920/31920 [==============================] - 3s - loss: 0.2416 - acc: 0.9320 - val_loss: 0.2368 - val_acc: 0.9262\n",
      "Epoch 6/10\n",
      "31920/31920 [==============================] - 3s - loss: 0.2240 - acc: 0.9367 - val_loss: 0.2233 - val_acc: 0.9321\n",
      "Epoch 7/10\n",
      "31920/31920 [==============================] - 3s - loss: 0.2068 - acc: 0.9407 - val_loss: 0.2104 - val_acc: 0.9357\n",
      "Epoch 8/10\n",
      "31920/31920 [==============================] - 3s - loss: 0.1913 - acc: 0.9461 - val_loss: 0.1997 - val_acc: 0.9387\n",
      "Epoch 9/10\n",
      "31920/31920 [==============================] - 3s - loss: 0.1771 - acc: 0.9506 - val_loss: 0.1872 - val_acc: 0.9411\n",
      "Epoch 10/10\n",
      "31920/31920 [==============================] - 3s - loss: 0.1640 - acc: 0.9540 - val_loss: 0.1785 - val_acc: 0.9429\n",
      "8400/8400 [==============================] - 0s     \n",
      "Using [512] number of hidden neurons yields. Accuracy score: 0.9412\n",
      "\n",
      "Train on 31920 samples, validate on 1680 samples\n",
      "Epoch 1/10\n",
      "31920/31920 [==============================] - 3s - loss: 0.4966 - acc: 0.8655 - val_loss: 0.3360 - val_acc: 0.9048\n",
      "Epoch 2/10\n",
      "31920/31920 [==============================] - 3s - loss: 0.3118 - acc: 0.9112 - val_loss: 0.2957 - val_acc: 0.9137\n",
      "Epoch 3/10\n",
      "31920/31920 [==============================] - 3s - loss: 0.2772 - acc: 0.9205 - val_loss: 0.2687 - val_acc: 0.9155\n",
      "Epoch 4/10\n",
      "31920/31920 [==============================] - 3s - loss: 0.2527 - acc: 0.9278 - val_loss: 0.2465 - val_acc: 0.9292\n",
      "Epoch 5/10\n",
      "31920/31920 [==============================] - 3s - loss: 0.2305 - acc: 0.9350 - val_loss: 0.2358 - val_acc: 0.9286\n",
      "Epoch 6/10\n",
      "31920/31920 [==============================] - 3s - loss: 0.2110 - acc: 0.9404 - val_loss: 0.2155 - val_acc: 0.9357\n",
      "Epoch 7/10\n",
      "31920/31920 [==============================] - 3s - loss: 0.1932 - acc: 0.9459 - val_loss: 0.2009 - val_acc: 0.9393\n",
      "Epoch 8/10\n",
      "31920/31920 [==============================] - 3s - loss: 0.1774 - acc: 0.9512 - val_loss: 0.1895 - val_acc: 0.9440\n",
      "Epoch 9/10\n",
      "31920/31920 [==============================] - 3s - loss: 0.1632 - acc: 0.9552 - val_loss: 0.1836 - val_acc: 0.9446\n",
      "Epoch 10/10\n",
      "31920/31920 [==============================] - 3s - loss: 0.1510 - acc: 0.9592 - val_loss: 0.1714 - val_acc: 0.9476\n",
      "8400/8400 [==============================] - 0s     \n",
      "Using [256] number of hidden neurons yields. Accuracy score: 0.9454\n",
      "\n",
      "Train on 31920 samples, validate on 1680 samples\n",
      "Epoch 1/10\n",
      "31920/31920 [==============================] - 3s - loss: 0.5168 - acc: 0.8630 - val_loss: 0.3357 - val_acc: 0.9030\n",
      "Epoch 2/10\n",
      "31920/31920 [==============================] - 3s - loss: 0.3111 - acc: 0.9107 - val_loss: 0.2855 - val_acc: 0.9125\n",
      "Epoch 3/10\n",
      "31920/31920 [==============================] - 3s - loss: 0.2703 - acc: 0.9223 - val_loss: 0.2552 - val_acc: 0.9220\n",
      "Epoch 4/10\n",
      "31920/31920 [==============================] - 3s - loss: 0.2401 - acc: 0.9312 - val_loss: 0.2340 - val_acc: 0.9351\n",
      "Epoch 5/10\n",
      "31920/31920 [==============================] - 3s - loss: 0.2161 - acc: 0.9386 - val_loss: 0.2131 - val_acc: 0.9435\n",
      "Epoch 6/10\n",
      "31920/31920 [==============================] - 3s - loss: 0.1956 - acc: 0.9452 - val_loss: 0.2018 - val_acc: 0.9429\n",
      "Epoch 7/10\n",
      "31920/31920 [==============================] - 3s - loss: 0.1791 - acc: 0.9503 - val_loss: 0.1865 - val_acc: 0.9476\n",
      "Epoch 8/10\n",
      "31920/31920 [==============================] - 3s - loss: 0.1644 - acc: 0.9544 - val_loss: 0.1789 - val_acc: 0.9476\n",
      "Epoch 9/10\n",
      "31920/31920 [==============================] - 3s - loss: 0.1518 - acc: 0.9578 - val_loss: 0.1695 - val_acc: 0.9476\n",
      "Epoch 10/10\n",
      "31920/31920 [==============================] - 3s - loss: 0.1412 - acc: 0.9619 - val_loss: 0.1625 - val_acc: 0.9512\n",
      "8400/8400 [==============================] - 0s     \n",
      "Using [128] number of hidden neurons yields. Accuracy score: 0.9483\n",
      "\n",
      "Train on 31920 samples, validate on 1680 samples\n",
      "Epoch 1/10\n",
      "31920/31920 [==============================] - 3s - loss: 0.5449 - acc: 0.8554 - val_loss: 0.3485 - val_acc: 0.9012\n",
      "Epoch 2/10\n",
      "31920/31920 [==============================] - 3s - loss: 0.3154 - acc: 0.9113 - val_loss: 0.2837 - val_acc: 0.9202\n",
      "Epoch 3/10\n",
      "31920/31920 [==============================] - 3s - loss: 0.2685 - acc: 0.9234 - val_loss: 0.2516 - val_acc: 0.9214\n",
      "Epoch 4/10\n",
      "31920/31920 [==============================] - 3s - loss: 0.2377 - acc: 0.9321 - val_loss: 0.2304 - val_acc: 0.9315\n",
      "Epoch 5/10\n",
      "31920/31920 [==============================] - 3s - loss: 0.2135 - acc: 0.9388 - val_loss: 0.2114 - val_acc: 0.9357\n",
      "Epoch 6/10\n",
      "31920/31920 [==============================] - 3s - loss: 0.1942 - acc: 0.9449 - val_loss: 0.1982 - val_acc: 0.9423\n",
      "Epoch 7/10\n",
      "31920/31920 [==============================] - 3s - loss: 0.1785 - acc: 0.9501 - val_loss: 0.1849 - val_acc: 0.9423\n",
      "Epoch 8/10\n",
      "31920/31920 [==============================] - 3s - loss: 0.1651 - acc: 0.9538 - val_loss: 0.1764 - val_acc: 0.9470\n",
      "Epoch 9/10\n",
      "31920/31920 [==============================] - 3s - loss: 0.1532 - acc: 0.9571 - val_loss: 0.1712 - val_acc: 0.9458\n",
      "Epoch 10/10\n",
      "31920/31920 [==============================] - 3s - loss: 0.1433 - acc: 0.9596 - val_loss: 0.1581 - val_acc: 0.9512\n",
      "8400/8400 [==============================] - 0s     \n",
      "Using [64] number of hidden neurons yields. Accuracy score: 0.9485\n",
      "\n",
      "Train on 31920 samples, validate on 1680 samples\n",
      "Epoch 1/10\n",
      "31920/31920 [==============================] - 3s - loss: 0.5879 - acc: 0.8494 - val_loss: 0.3675 - val_acc: 0.8982\n",
      "Epoch 2/10\n",
      "31920/31920 [==============================] - 3s - loss: 0.3271 - acc: 0.9102 - val_loss: 0.2959 - val_acc: 0.9149\n",
      "Epoch 3/10\n",
      "31920/31920 [==============================] - 3s - loss: 0.2780 - acc: 0.9222 - val_loss: 0.2647 - val_acc: 0.9226\n",
      "Epoch 4/10\n",
      "31920/31920 [==============================] - 3s - loss: 0.2481 - acc: 0.9306 - val_loss: 0.2408 - val_acc: 0.9333\n",
      "Epoch 5/10\n",
      "31920/31920 [==============================] - 3s - loss: 0.2257 - acc: 0.9376 - val_loss: 0.2268 - val_acc: 0.9381\n",
      "Epoch 6/10\n",
      "31920/31920 [==============================] - 3s - loss: 0.2085 - acc: 0.9421 - val_loss: 0.2116 - val_acc: 0.9440\n",
      "Epoch 7/10\n",
      "31920/31920 [==============================] - 3s - loss: 0.1940 - acc: 0.9470 - val_loss: 0.2033 - val_acc: 0.9452\n",
      "Epoch 8/10\n",
      "31920/31920 [==============================] - 3s - loss: 0.1816 - acc: 0.9498 - val_loss: 0.1938 - val_acc: 0.9482\n",
      "Epoch 9/10\n",
      "31920/31920 [==============================] - 3s - loss: 0.1714 - acc: 0.9526 - val_loss: 0.1903 - val_acc: 0.9482\n",
      "Epoch 10/10\n",
      "31920/31920 [==============================] - 3s - loss: 0.1628 - acc: 0.9547 - val_loss: 0.1879 - val_acc: 0.9458\n",
      "8400/8400 [==============================] - 0s     \n",
      "Using [32] number of hidden neurons yields. Accuracy score: 0.9396\n",
      "\n",
      "Train on 31920 samples, validate on 1680 samples\n",
      "Epoch 1/10\n",
      "31920/31920 [==============================] - 3s - loss: 0.6751 - acc: 0.8353 - val_loss: 0.4077 - val_acc: 0.8929\n",
      "Epoch 2/10\n",
      "31920/31920 [==============================] - 3s - loss: 0.3600 - acc: 0.9049 - val_loss: 0.3196 - val_acc: 0.9101\n",
      "Epoch 3/10\n",
      "31920/31920 [==============================] - 3s - loss: 0.3040 - acc: 0.9168 - val_loss: 0.2844 - val_acc: 0.9202\n",
      "Epoch 4/10\n",
      "31920/31920 [==============================] - 3s - loss: 0.2735 - acc: 0.9251 - val_loss: 0.2576 - val_acc: 0.9208\n",
      "Epoch 5/10\n",
      "31920/31920 [==============================] - 3s - loss: 0.2531 - acc: 0.9294 - val_loss: 0.2460 - val_acc: 0.9310\n",
      "Epoch 6/10\n",
      "31920/31920 [==============================] - 3s - loss: 0.2372 - acc: 0.9344 - val_loss: 0.2364 - val_acc: 0.9315\n",
      "Epoch 7/10\n",
      "31920/31920 [==============================] - 3s - loss: 0.2249 - acc: 0.9367 - val_loss: 0.2261 - val_acc: 0.9321\n",
      "Epoch 8/10\n",
      "31920/31920 [==============================] - 3s - loss: 0.2143 - acc: 0.9406 - val_loss: 0.2254 - val_acc: 0.9363\n",
      "Epoch 9/10\n",
      "31920/31920 [==============================] - 3s - loss: 0.2054 - acc: 0.9430 - val_loss: 0.2173 - val_acc: 0.9369\n",
      "Epoch 10/10\n",
      "31920/31920 [==============================] - 3s - loss: 0.1974 - acc: 0.9453 - val_loss: 0.2181 - val_acc: 0.9339\n",
      "8400/8400 [==============================] - 0s     \n",
      "Using [16] number of hidden neurons yields. Accuracy score: 0.9305\n",
      "\n",
      "Train on 31920 samples, validate on 1680 samples\n",
      "Epoch 1/10\n",
      "31920/31920 [==============================] - 3s - loss: 0.9143 - acc: 0.7975 - val_loss: 0.5725 - val_acc: 0.8679\n",
      "Epoch 2/10\n",
      "31920/31920 [==============================] - 3s - loss: 0.4821 - acc: 0.8799 - val_loss: 0.4302 - val_acc: 0.8875\n",
      "Epoch 3/10\n",
      "31920/31920 [==============================] - 3s - loss: 0.3984 - acc: 0.8942 - val_loss: 0.3778 - val_acc: 0.9000\n",
      "Epoch 4/10\n",
      "31920/31920 [==============================] - 3s - loss: 0.3587 - acc: 0.9017 - val_loss: 0.3469 - val_acc: 0.9077\n",
      "Epoch 5/10\n",
      "31920/31920 [==============================] - 3s - loss: 0.3345 - acc: 0.9081 - val_loss: 0.3352 - val_acc: 0.9065\n",
      "Epoch 6/10\n",
      "31920/31920 [==============================] - 3s - loss: 0.3178 - acc: 0.9123 - val_loss: 0.3209 - val_acc: 0.9131\n",
      "Epoch 7/10\n",
      "31920/31920 [==============================] - 3s - loss: 0.3048 - acc: 0.9143 - val_loss: 0.3136 - val_acc: 0.9101\n",
      "Epoch 8/10\n",
      "31920/31920 [==============================] - 3s - loss: 0.2941 - acc: 0.9167 - val_loss: 0.3106 - val_acc: 0.9125\n",
      "Epoch 9/10\n",
      "31920/31920 [==============================] - 3s - loss: 0.2862 - acc: 0.9176 - val_loss: 0.3100 - val_acc: 0.9131\n",
      "Epoch 10/10\n",
      "31920/31920 [==============================] - 3s - loss: 0.2788 - acc: 0.9202 - val_loss: 0.3049 - val_acc: 0.9131\n",
      "8400/8400 [==============================] - 0s     \n",
      "Using [8] number of hidden neurons yields. Accuracy score: 0.9081\n",
      "\n",
      "Train on 31920 samples, validate on 1680 samples\n",
      "Epoch 1/10\n",
      "31920/31920 [==============================] - 3s - loss: 1.2546 - acc: 0.6927 - val_loss: 0.8366 - val_acc: 0.7988\n",
      "Epoch 2/10\n",
      "31920/31920 [==============================] - 3s - loss: 0.7538 - acc: 0.7991 - val_loss: 0.6797 - val_acc: 0.8185\n",
      "Epoch 3/10\n",
      "31920/31920 [==============================] - 3s - loss: 0.6600 - acc: 0.8143 - val_loss: 0.6277 - val_acc: 0.8304\n",
      "Epoch 4/10\n",
      "31920/31920 [==============================] - 3s - loss: 0.6239 - acc: 0.8230 - val_loss: 0.6077 - val_acc: 0.8268\n",
      "Epoch 5/10\n",
      "31920/31920 [==============================] - 3s - loss: 0.6027 - acc: 0.8256 - val_loss: 0.5839 - val_acc: 0.8351\n",
      "Epoch 6/10\n",
      "31920/31920 [==============================] - 3s - loss: 0.5892 - acc: 0.8306 - val_loss: 0.5785 - val_acc: 0.8315\n",
      "Epoch 7/10\n",
      "31920/31920 [==============================] - 3s - loss: 0.5790 - acc: 0.8316 - val_loss: 0.5758 - val_acc: 0.8321\n",
      "Epoch 8/10\n",
      "31920/31920 [==============================] - 3s - loss: 0.5709 - acc: 0.8342 - val_loss: 0.5739 - val_acc: 0.8339\n",
      "Epoch 9/10\n",
      "31920/31920 [==============================] - 3s - loss: 0.5654 - acc: 0.8342 - val_loss: 0.5581 - val_acc: 0.8345\n",
      "Epoch 10/10\n",
      "31920/31920 [==============================] - 3s - loss: 0.5599 - acc: 0.8374 - val_loss: 0.5736 - val_acc: 0.8256\n",
      "8400/8400 [==============================] - 0s     \n",
      "Using [4] number of hidden neurons yields. Accuracy score: 0.8177\n",
      "\n",
      "Train on 31920 samples, validate on 1680 samples\n",
      "Epoch 1/10\n",
      "31920/31920 [==============================] - 3s - loss: 1.6598 - acc: 0.3836 - val_loss: 1.4273 - val_acc: 0.4155\n",
      "Epoch 2/10\n",
      "31920/31920 [==============================] - 3s - loss: 1.3708 - acc: 0.4233 - val_loss: 1.3183 - val_acc: 0.4298\n",
      "Epoch 3/10\n",
      "31920/31920 [==============================] - 3s - loss: 1.2975 - acc: 0.4403 - val_loss: 1.2685 - val_acc: 0.4536\n",
      "Epoch 4/10\n",
      "31920/31920 [==============================] - 3s - loss: 1.2581 - acc: 0.4591 - val_loss: 1.2310 - val_acc: 0.4542\n",
      "Epoch 5/10\n",
      "31920/31920 [==============================] - 2s - loss: 1.2294 - acc: 0.4855 - val_loss: 1.2125 - val_acc: 0.5048\n",
      "Epoch 6/10\n",
      "31920/31920 [==============================] - 2s - loss: 1.2047 - acc: 0.5040 - val_loss: 1.1922 - val_acc: 0.5310\n",
      "Epoch 7/10\n",
      "31920/31920 [==============================] - 2s - loss: 1.1818 - acc: 0.5237 - val_loss: 1.2201 - val_acc: 0.5262\n",
      "Epoch 8/10\n",
      "31920/31920 [==============================] - 2s - loss: 1.1645 - acc: 0.5443 - val_loss: 1.1387 - val_acc: 0.5780\n",
      "Epoch 9/10\n",
      "31920/31920 [==============================] - 2s - loss: 1.1491 - acc: 0.5534 - val_loss: 1.1416 - val_acc: 0.5542\n",
      "Epoch 10/10\n",
      "31920/31920 [==============================] - 2s - loss: 1.1351 - acc: 0.5653 - val_loss: 1.1171 - val_acc: 0.6000\n",
      "8400/8400 [==============================] - 0s     \n",
      "Using [2] number of hidden neurons yields. Accuracy score: 0.5676\n",
      "\n",
      "Train on 31920 samples, validate on 1680 samples\n",
      "Epoch 1/10\n",
      "31920/31920 [==============================] - 3s - loss: 1.9758 - acc: 0.2119 - val_loss: 1.8660 - val_acc: 0.2583\n",
      "Epoch 2/10\n",
      "31920/31920 [==============================] - 2s - loss: 1.8501 - acc: 0.2623 - val_loss: 1.8218 - val_acc: 0.3000\n",
      "Epoch 3/10\n",
      "31920/31920 [==============================] - 2s - loss: 1.8202 - acc: 0.2602 - val_loss: 1.7980 - val_acc: 0.3018\n",
      "Epoch 4/10\n",
      "31920/31920 [==============================] - 2s - loss: 1.8035 - acc: 0.2698 - val_loss: 1.7855 - val_acc: 0.2565\n",
      "Epoch 5/10\n",
      "31920/31920 [==============================] - 2s - loss: 1.7889 - acc: 0.2808 - val_loss: 1.7755 - val_acc: 0.3083\n",
      "Epoch 6/10\n",
      "31920/31920 [==============================] - 2s - loss: 1.7775 - acc: 0.2811 - val_loss: 1.7672 - val_acc: 0.3357\n",
      "Epoch 7/10\n",
      "31920/31920 [==============================] - 2s - loss: 1.7674 - acc: 0.3117 - val_loss: 1.7552 - val_acc: 0.3375\n",
      "Epoch 8/10\n",
      "31920/31920 [==============================] - 2s - loss: 1.7580 - acc: 0.3014 - val_loss: 1.7477 - val_acc: 0.2982\n",
      "Epoch 9/10\n",
      "31920/31920 [==============================] - 2s - loss: 1.7489 - acc: 0.3145 - val_loss: 1.7322 - val_acc: 0.3476\n",
      "Epoch 10/10\n",
      "31920/31920 [==============================] - 2s - loss: 1.7419 - acc: 0.3189 - val_loss: 1.8143 - val_acc: 0.2798\n",
      "8400/8400 [==============================] - 0s     \n",
      "Using [1] number of hidden neurons yields. Accuracy score: 0.2919\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_hiddens = [512, 256, 128, 64, 32, 16, 8, 4, 2, 1]\n",
    "scores = []\n",
    "for n_hidden in n_hiddens:\n",
    "    # Build a simple neural network.\n",
    "    model = Sequential()\n",
    "    model.add(Dense(input_dim = X.shape[1], output_dim = n_hidden))\n",
    "    model.add(Activation('tanh'))\n",
    "    model.add(Dense(output_dim = 10))\n",
    "    model.add(Activation('softmax'))\n",
    "    sgd = SGD(lr=0.2, decay=1e-7, momentum=0.1, nesterov=True)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='sgd')\n",
    "\n",
    "    model.fit(X_train, Y_train, nb_epoch = 10, batch_size = 10, show_accuracy = True, verbose = 1, validation_split = 0.05)\n",
    "    Y_cv_pred = model.predict_classes(X_cv, batch_size = 10, verbose = 1)\n",
    "\n",
    "    score = accuracy_score(raw_Y_cv, Y_cv_pred)\n",
    "    scores.append(score)\n",
    "    print('Using [%d] number of hidden neurons yields. Accuracy score: %.4f' % (n_hidden, score))\n",
    "    print('')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f98e4e59be0>]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA+AAAAIICAYAAADuR4QmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f98e4d4d2b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the results for comparison\n",
    "\n",
    "fig = plt.figure()\n",
    "fig.suptitle('(Test validation score) against (Number of hidden neurons) on MNIST data', fontsize = 20)\n",
    "fig.set_figwidth(17)\n",
    "fig.set_figheight(8)\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "ax.plot(n_hiddens, scores, '-o', markersize = 10, markerfacecolor = 'r')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What can we learn?\n",
    "\n",
    "From here we can see the the number of hidden neurons does affect the model performance. When a neural network has too few hidden neurons (< 16), it does not have the capacity to learn enough of the underlying patterns to distinguish between 0 - 9 effectively. When the neural network has >= 16 neurons, the neural network start to do better. At increasing number of hidden neurons (>= 128), the number of hidden neurons does not help too much for this problem.\n",
    "\n",
    "Note that I am only illustrating one single parameter here. There are a lot of other parameters like how the neural network is structured, the learning rate, and many other parameters to tune. Do play around with it to learn how neural networks behave."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
